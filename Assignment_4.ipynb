{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tanishq7642/Machine-Learning-UML501-/blob/main/Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4R30dm98PPg"
      },
      "source": [
        "> **Q1. Write a Python program to scrape all available books from the website (https://books.toscrape.com/) Books to Scrape. For each book, extract the following details:**\n",
        ">\n",
        "> 1.  **Title**\n",
        "> 2.  **Price**\n",
        "> 3.  **Availability (In stock / Out of stock)**\n",
        "> 4.  **Star Rating (One, Two, Three, Four, Five)**\n",
        ">\n",
        "> **Store the scraped results into a Pandas DataFrame and export them to a CSV file named `books.csv`.**\n",
        ">\n",
        "> *(Note: Use the requests library to fetch the HTML page. Use BeautifulSoup to parse and extract book details and handle pagination so that books from all pages are scraped)*"
      ],
      "id": "Q4R30dm98PPg"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MOC6LM38PPm",
        "outputId": "d880b854-e63f-42ed-ded6-ceb64b00b614"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting to scrape books...\n",
            "Saved 1000 books to books.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "base_url = \"https://books.toscrape.com/catalogue/\"\n",
        "current_url = base_url + \"page-1.html\"\n",
        "\n",
        "all_books_data = []\n",
        "\n",
        "print(\"Starting to scrape books...\")\n",
        "\n",
        "while current_url:\n",
        "    response = requests.get(current_url)\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    books_on_page = soup.find_all(\"article\", class_=\"product_pod\")\n",
        "\n",
        "    for book in books_on_page:\n",
        "        title = book.h3.a[\"title\"]\n",
        "        price = book.find(\"p\", class_=\"price_color\").text\n",
        "        availability = book.find(\"p\", class_=\"instock availability\").text.strip()\n",
        "\n",
        "        rating_classes = book.find(\"p\", class_=\"star-rating\")[\"class\"]\n",
        "        rating = rating_classes[1]\n",
        "\n",
        "        all_books_data.append({\n",
        "            \"Title\": title,\n",
        "            \"Price\": price,\n",
        "            \"Availability\": availability,\n",
        "            \"Rating\": rating\n",
        "        })\n",
        "\n",
        "    next_page_element = soup.find(\"li\", class_=\"next\")\n",
        "\n",
        "    if next_page_element:\n",
        "        next_page_href = next_page_element.a[\"href\"]\n",
        "        current_url = base_url + next_page_href\n",
        "    else:\n",
        "        current_url = None\n",
        "\n",
        "df = pd.DataFrame(all_books_data)\n",
        "df.to_csv(\"books.csv\", index=False)\n",
        "\n",
        "print(f\"Saved {len(all_books_data)} books to books.csv\")"
      ],
      "id": "6MOC6LM38PPm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnAaXxS28PPq"
      },
      "source": [
        "> **Q2. Write a Python program to scrape the IMDB Top 250 Movies list (https://www.imdb.com/chart/top/). For each movie, extract the following details:**\n",
        ">\n",
        "> 1.  **Rank (1-250)**\n",
        "> 2.  **Movie Title**\n",
        "> 3.  **Year of Release**\n",
        "> 4.  **IMDB Rating**\n",
        ">\n",
        "> **Store the results in a Pandas DataFrame and export it to a CSV file named `imdb_top250.csv`.**\n",
        ">\n",
        "> *(Note: Use Selenium/Playwright to scrape the required details from this website)*"
      ],
      "id": "cnAaXxS28PPq"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL-FOOSb8PPr",
        "outputId": "ab54d234-8c6a-41d4-b6db-2c830771b6bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting to scrape IMDB...\n",
            "Saved 0 movies to imdb_top250.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "url = \"https://www.imdb.com/chart/top/\"\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"}\n",
        "\n",
        "response = requests.get(url, headers=headers)\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "movie_list = []\n",
        "\n",
        "movies = soup.find_all('li', class_=re.compile(\"ipc-metadata-list-summary-item\"))\n",
        "\n",
        "print(\"Starting to scrape IMDB...\")\n",
        "\n",
        "for movie in movies:\n",
        "    title_element = movie.find(\"h3\", class_=re.compile(\"ipc-title__text\"))\n",
        "    metadata_spans = movie.find_all(\"span\", class_=re.compile(\"meta-info-item\"))\n",
        "    rating_element = movie.find(\"span\", class_=re.compile(\"ipc-rating-star\"))\n",
        "\n",
        "    if title_element and len(metadata_spans) > 0 and rating_element:\n",
        "        title_text = title_element.text\n",
        "\n",
        "        try:\n",
        "            rank_str, title_str = title_text.split(\". \", 1)\n",
        "            rank = int(rank_str)\n",
        "        except ValueError:\n",
        "            continue\n",
        "\n",
        "        year = metadata_spans[0].text\n",
        "\n",
        "        rating = rating_element.text.split(\"(\")[0].strip()\n",
        "\n",
        "        movie_list.append({\n",
        "            \"Rank\": rank,\n",
        "            \"Title\": title_str,\n",
        "            \"Year\": year,\n",
        "            \"Rating\": rating\n",
        "        })\n",
        "\n",
        "df = pd.DataFrame(movie_list)\n",
        "df.to_csv(\"imdb_top250.csv\", index=False)\n",
        "\n",
        "print(f\"Saved {len(movie_list)} movies to imdb_top250.csv\")"
      ],
      "id": "dL-FOOSb8PPr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcxNc0wP8PPs"
      },
      "source": [
        "> **Q3. Write a Python program to scrape the weather information for top world cities from the given website (https://www.timeanddate.com/weather/). For each city, extract the following details:**\n",
        ">\n",
        "> 1.  **City Name**\n",
        "> 2.  **Temperature**\n",
        "> 3.  **Weather Condition (e.g., Clear, Cloudy, Rainy, etc.)**\n",
        ">\n",
        "> **Store the results in a Pandas DataFrame and export it to a CSV file named `weather.csv`.**"
      ],
      "id": "hcxNc0wP8PPs"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDUul8Dx8PPs",
        "outputId": "f31c4190-6277-402d-d17c-a677fe7a1bdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting to scrape weather...\n",
            "Error: Could not find the weather table. The website structure might have changed.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://www.timeanddate.com/weather/\"\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"}\n",
        "\n",
        "response = requests.get(url, headers=headers)\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "weather_data = []\n",
        "table = soup.find(\"table\", class_=\"zebra fw tb-wc\")\n",
        "\n",
        "print(\"Starting to scrape weather...\")\n",
        "\n",
        "try:\n",
        "    rows = table.tbody.find_all(\"tr\")\n",
        "    for row in rows:\n",
        "        cells = row.find_all(\"td\")\n",
        "\n",
        "        if len(cells) > 2:\n",
        "            city = cells[0].a.text\n",
        "            temp = cells[1].text\n",
        "            condition = cells[2].text\n",
        "\n",
        "            weather_data.append({\n",
        "                \"City\": city,\n",
        "                \"Temperature\": temp,\n",
        "                \"Condition\": condition\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(weather_data)\n",
        "    df.to_csv(\"weather.csv\", index=False)\n",
        "    print(f\"Saved {len(weather_data)} cities to weather.csv\")\n",
        "\n",
        "except AttributeError:\n",
        "    print(\"Error: Could not find the weather table. The website structure might have changed.\")\n"
      ],
      "id": "iDUul8Dx8PPs"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}