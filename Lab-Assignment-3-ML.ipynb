{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Lab Assignment 3 - Machine Learning (UML501)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Q1: K-Fold Cross Validation for Multiple Linear Regression (Least Squares Fit)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Download the USA Housing dataset and implement **5-fold cross validation** using Least Squares Error Fit."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import KFold, train_test_split\n\n# Step a: Load dataset\ndf = pd.read_csv('USA_Housing.csv')\n\n# Separate input features (X) and target (y)\nX = df.drop(\"Price\", axis=1).values\ny = df[\"Price\"].values.reshape(-1, 1)\n\n# Step b: Scale input features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Step c: 5-fold cross-validation\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n\nbest_beta = None\nbest_r2 = -np.inf\nr2_scores = []\n\n# Step d: Perform CV\nfor fold, (train_idx, test_idx) in enumerate(kf.split(X_scaled)):\n    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n    y_train, y_test = y[train_idx], y[test_idx]\n\n    # Add bias term\n    X_train_bias = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n    X_test_bias = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n\n    # Compute beta using Least Squares\n    beta = np.linalg.inv(X_train_bias.T @ X_train_bias) @ (X_train_bias.T @ y_train)\n\n    # Predictions\n    y_pred = X_test_bias @ beta\n\n    # R\u00b2 score\n    r2 = r2_score(y_test, y_pred)\n    r2_scores.append(r2)\n    print(f\"Fold {fold+1}: R\u00b2 = {r2:.4f}\")\n\n    if r2 > best_r2:\n        best_r2 = r2\n        best_beta = beta\n\nprint(\"\\nAverage R\u00b2 across folds:\", np.mean(r2_scores))\nprint(\"Best R\u00b2 score:\", best_r2)\n\n# Step e: Train on 70%, Test on 30% with best beta\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\nX_train_bias = np.c_[np.ones((X_train.shape[0], 1)), X_train]\nX_test_bias = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n\ny_train_pred = X_train_bias @ best_beta\ny_test_pred = X_test_bias @ best_beta\n\nprint(\"\\nFinal Model Performance:\")\nprint(\"Train R\u00b2:\", r2_score(y_train, y_train_pred))\nprint(\"Test R\u00b2:\", r2_score(y_test, y_test_pred))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Q2: Concept of Validation Set (Gradient Descent Optimization)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Use the same dataset, split into Training (56%), Validation (14%), and Test (30%). Train using **Gradient Descent** with learning rates {0.001, 0.01, 0.1, 1}."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n# Gradient Descent Implementation for Linear Regression\ndef gradient_descent(X, y, lr=0.01, epochs=1000):\n    m, n = X.shape\n    beta = np.zeros((n, 1))\n    for _ in range(epochs):\n        gradients = (2/m) * X.T @ (X @ beta - y)\n        beta -= lr * gradients\n    return beta\n\n# Split into train (56%), validation (14%), test (30%)\nX_temp, X_test, y_temp, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)\n\n# Add bias\nX_train_bias = np.c_[np.ones((X_train.shape[0], 1)), X_train]\nX_val_bias = np.c_[np.ones((X_val.shape[0], 1)), X_val]\nX_test_bias = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n\nlrs = [0.001, 0.01, 0.1, 1]\nbest_beta, best_r2_val = None, -np.inf\n\nfor lr in lrs:\n    beta = gradient_descent(X_train_bias, y_train, lr=lr, epochs=1000)\n    val_pred = X_val_bias @ beta\n    test_pred = X_test_bias @ beta\n    r2_val = r2_score(y_val, val_pred)\n    r2_test = r2_score(y_test, test_pred)\n    print(f\"Learning Rate {lr}: Validation R\u00b2 = {r2_val:.4f}, Test R\u00b2 = {r2_test:.4f}\")\n    if r2_val > best_r2_val:\n        best_r2_val = r2_val\n        best_beta = beta\n\nprint(\"\\nBest Beta coefficients found with Validation R\u00b2:\", best_r2_val)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Q3: Pre-processing and Multiple Linear Regression (Car Price Prediction)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Download the Car Price dataset and perform preprocessing as described. Train regression before and after PCA."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n# Load Car Price dataset\ncolumns = [\"symboling\",\"normalized_losses\",\"make\",\"fuel_type\",\"aspiration\",\"num_doors\",\n           \"body_style\",\"drive_wheels\",\"engine_location\",\"wheel_base\",\"length\",\"width\",\n           \"height\",\"curb_weight\",\"engine_type\",\"num_cylinders\",\"engine_size\",\"fuel_system\",\n           \"bore\",\"stroke\",\"compression_ratio\",\"horsepower\",\"peak_rpm\",\"city_mpg\",\"highway_mpg\",\"price\"]\n\ncar_df = pd.read_csv(\"imports-85.data\", names=columns, na_values=\"?\")\n\n# Step 1: Handle missing values\ncar_df = car_df.dropna(subset=[\"price\"])\ncar_df = car_df.fillna(car_df.median(numeric_only=True))\n\n# Step 2: Convert categorical values\ncar_df[\"num_doors\"] = car_df[\"num_doors\"].replace({\"two\":2, \"four\":4})\ncar_df[\"num_cylinders\"] = car_df[\"num_cylinders\"].replace({\"two\":2,\"three\":3,\"four\":4,\"five\":5,\"six\":6,\"eight\":8,\"twelve\":12})\n\ncar_df = pd.get_dummies(car_df, columns=[\"body_style\",\"drive_wheels\"])\nfrom sklearn.preprocessing import LabelEncoder\nfor col in [\"make\",\"aspiration\",\"engine_location\",\"fuel_type\"]:\n    car_df[col] = LabelEncoder().fit_transform(car_df[col].astype(str))\n\ncar_df[\"fuel_system\"] = car_df[\"fuel_system\"].apply(lambda x: 1 if \"pfi\" in str(x) else 0)\ncar_df[\"engine_type\"] = car_df[\"engine_type\"].apply(lambda x: 1 if \"ohc\" in str(x) else 0)\n\n# Step 3: Features and target\nX_car = car_df.drop(\"price\", axis=1)\ny_car = car_df[\"price\"].astype(float)\n\n# Scale features\nX_car_scaled = StandardScaler().fit_transform(X_car)\n\n# Train/Test split\nX_train, X_test, y_train, y_test = train_test_split(X_car_scaled, y_car, test_size=0.3, random_state=42)\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.decomposition import PCA\n\n# Train Linear Regression\nlr = LinearRegression()\nlr.fit(X_train, y_train)\nprint(\"Without PCA - Test R\u00b2:\", lr.score(X_test, y_test))\n\n# PCA reduction\npca = PCA(n_components=10)\nX_car_pca = pca.fit_transform(X_car_scaled)\nX_train_pca, X_test_pca, y_train, y_test = train_test_split(X_car_pca, y_car, test_size=0.3, random_state=42)\n\nlr_pca = LinearRegression()\nlr_pca.fit(X_train_pca, y_train)\nprint(\"With PCA - Test R\u00b2:\", lr_pca.score(X_test_pca, y_test))\n"]}], "metadata": {"colab": {"name": "Lab-Assignment-3-ML.ipynb", "provenance": []}, "kernelspec": {"name": "python3", "display_name": "Python 3"}}, "nbformat": 4, "nbformat_minor": 0}